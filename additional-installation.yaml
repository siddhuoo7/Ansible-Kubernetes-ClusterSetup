---
- hosts: master-nodes
  tasks:
  - name: Include vars
    include_vars: "config_var.yaml"
  - name: install git
    yum:
      name: git
      state: present
  - name: clone addon repo
    shell: |
      rm -rf /root/kube_additional/*
      git clone http://root:Ecssupport09@192.168.75.53/labs/deployment-addons.git
      mkdir /root/kube_additional -p
      cp -rf deployment-addons/* /root/kube_additional/
      rm -rf deployment-addons
  - name: create nameSpace load_balancer
    shell: |
      kubectl create ns {{ load_balancer_ns }}
    ignore_errors: yes
  - name: create nameSpace logging
    shell: |
      kubectl create ns {{ logging_ns }}
    ignore_errors: yes
  - name: create nameSpace monitoring
    shell: |
      kubectl create ns {{ monitoring_ns }}
    ignore_errors: yes
  - name: create nameSpace messaging
    shell: |
      kubectl create ns {{ messaging_ns }}
    ignore_errors: yes
  - name: create service deployment nameSpace 
    shell: |
      kubectl create ns {{ deployment_ns }}
    ignore_errors: yes
  - name: create zeebe nameSpace 
    shell: |
      kubectl create ns {{ zeebe_ns }}
    ignore_errors: yes
  - name: create redis nameSpace 
    shell: |
      kubectl create ns {{ redis_ns }}
    ignore_errors: yes      
    
  - name: Deploying Rancher in docker
    shell: docker run --name rancher --restart=always -d -p 7000:80 -p 7010:443 -v rancher-data:/var/lib/rancher rancher/rancher:v2.3.5
    ignore_errors: yes
    when:
      - Rancher_dashboard == "enabled"
- 
  hosts: master-nodes
  tasks:
    - 
      name: "Install Docker-Compose"
      shell: |
          curl -L "https://github.com/docker/compose/releases/download/1.25.4/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
          sudo chmod +x /usr/local/bin/docker-compose
    - 
      name: "install MetalLB Load Balancer"
      shell: |
          sed -i "s|namespace: load-balancer|namespace: {{ load_balancer_ns }}|g" /root/kube_additional/load-balancer/metallb.yaml
          kubectl create -f /root/kube_additional/load-balancer/metallb.yaml
          kubectl create secret generic -n {{ load_balancer_ns }} memberlist --from-literal=secretkey="$(openssl rand -base64 128)"
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: ConfigMap
          metadata:
            namespace: {{ load_balancer_ns }}
            name: config
          data:
            config: |
              address-pools:
              - name: default
                protocol: layer2
                addresses:
                - {{ Loadbalancer_ip_range }}
          EOF
      ignore_errors: yes
    - name: "Master ip address"
      debug:
        msg: "{{ ansible_eth0.ipv4.address }}"
    - 
      name: "implementing nfs client provisioning"
      shell: |
          rm -rf /srv/nfs/kubedata/*
          mkdir /srv/nfs/kubedata -p
          chown nobody: /srv/nfs/kubedata
          sudo systemctl enable nfs-server
          sudo systemctl start nfs-server
          cat > /etc/exports << EOF
          /srv/nfs/kubedata   *(rw,sync,no_subtree_check,no_root_squash,no_all_squash,insecure)
          EOF
          exportfs -rav
          helm repo add stable https://charts.helm.sh/stable
          helm repo update
          #helm install nfs-client-provisioner stable/nfs-client-provisioner --set nfs.server=172.27.11.121 --set nfs.path=/srv/nfs/kubedata --set storageClass.defaultClass=true --namespace {{ operations_ns }}
          helm install nfs-client-provisioner stable/nfs-client-provisioner --set nfs.server={{ ansible_eth0.ipv4.address }} --set nfs.path=/srv/nfs/kubedata --set storageClass.defaultClass=true --namespace {{ operations_ns }}
          kubectl wait --for=condition=Ready pods --all -n {{ operations_ns }} --timeout=300s
          kubectl apply -f /root/kube_additional/logging/logging-pvc.yaml
      ignore_errors: yes
    - 
      name: "Deploying elk in Kubernetes"
      shell: |
          helm repo add elastic https://helm.elastic.co
          helm install  elasticsearch elastic/elasticsearch --set replicas={{ elk_replicas }} -n {{ logging_ns }}
          kubectl wait --for=condition=Ready pods --all -n {{ logging_ns }} --timeout=60s
          helm install  kibana elastic/kibana --set service.type=LoadBalancer -n {{ logging_ns }}
      ignore_errors: yes
      when: 
        - Cluster_Logging == "enabled"      
    - 
      name: "Deploying the elastic logShipper"
      shell: |
          #cd /root/kube_additional/logging/fluent-bit
          #kubectl apply -f .
          sed -i "s|namespace: logging|namespace: {{ logging_ns }}|g" /root/kube_additional/logging/filebeat.yml
          kubectl wait --for=condition=Ready pods --all -n {{ logging_ns }} --timeout=60s
          kubectl create -f /root/kube_additional/logging/filebeat.yml
      ignore_errors: yes
      when: 
        - Cluster_Logging == "enabled" 
    - 
      name: "Deploying Prometheus and Grafana"
      shell: |
          helm install grafana stable/grafana --values /root/kube_additional/monitoring/grafana.value -n {{ monitoring_ns }}
          helm install prometheus stable/prometheus --values  /root/kube_additional/monitoring/prometheus.value -n {{ monitoring_ns }}
      when: 
        - Cluster_Monitoring == "enabled"       
    - 
      name: "Deploying Kubernetes Event Exporter"
      shell: |
          sed -i "s|slack_token|{{ slack_token }}|g" /root/kube_additional/monitoring/eventExporter/01-config.yaml
          sed -i "s|slack_channel|{{ slack_channel }}|g" /root/kube_additional/monitoring/eventExporter/01-config.yaml
          kubectl create -f /root/kube_additional/monitoring/eventExporter
          helm install --name kubewatch bitnami/kubewatch --set='rbac.create=true,slack.channel={{ slack_channel }},slack.token={{ slack_token }},resourcesToWatch.pod=true,resourcesToWatch.daemonset=true,resourcesToWatch.persistentvolume=true,resourcesToWatch.services'
      when: 
        - Cluster_Monitoring == "enabled"   
    - name: "installing pod auto scaler"
      shell: |
          kubectl apply -f /root/kube_additional/hpa
      when: 
        - Auto_scaling == "enabled"         
    - name: "Install WeaveScope"
      shell: |
          sed -i "s|namespace: monitoring|namespace: {{ monitoring_ns }}|g" /root/kube_additional/monitoring/weave.yaml
          kubectl apply -f /root/kube_additional/monitoring/weave.yaml
      when: 
        - Cluster_Monitoring == "enableAll"   
    - name: "Deploying database"
      shell: |
          kubectl create ns mongo
          kubectl apply -f /root/kube_additional/database/mongodb-workload.yaml -n mongo
          kubectl apply -f /root/kube_additional/database/mongodbDnsMap.yaml -n {{ deployment_ns }}
          #kubectl apply -f /root/kube_additional/database/pgadmin-workload.yaml -f /root/kube_additional/database/postgres-workload.yaml
      when: 
        - Mongo == "enabled"         
      ignore_errors: yes       
    - name: "Deploying kafka"
      shell: |
          #helm repo add confluentinc https://confluentinc.github.io/cp-helm-charts/
          #helm repo update
          #helm install kafka confluentinc/cp-helm-charts -f /root/value.yaml -n {{ messaging_ns }}
          #kubectl apply -f 'https://strimzi.io/install/latest?namespace=kafka' -n kafka
          helm repo add strimzi https://strimzi.io/charts/
          helm install kafka strimzi/strimzi-kafka-operator -n {{ messaging_ns }}
          kubectl wait --for=condition=Ready pods --all -n {{ messaging_ns }}
          kubectl apply -f /root/kube_additional/messaging/kafka-prod.yaml -n {{ messaging_ns }}
          kubectl apply -f /root/kube_additional/messaging/kafkaMapDns.yml -n {{ deployment_ns }}
      when: 
        - Kafka == "enabled"      
      ignore_errors: yes          
    - name: "Installing Kong API Gateway"
      shell: |
          kubectl create -f /root/kube_additional/load-balancer/kong.yaml
          kubectl patch -n kong svc kong-proxy --type='json' -p '[{"op":"replace","path":"/spec/loadBalancerIP","value":"{{kong_loadBalancerIP}}"}]'
    - name: "Installing Zeebe"
      shell: |
          helm repo add zeebe https://helm.zeebe.io
          helm repo update
          #helm install ecsfin zeebe/zeebe-full -n {{ zeebe_ns }}
          helm install ecsfin zeebe/zeebe-cluster -n {{ zeebe_ns }}
          kubectl apply -f /root/kube_additional/database/zeebeMapDns.yaml -n {{ deployment_ns }}
      when: 
        - Zeebe == "enabled"       
      ignore_errors: yes
    - name: "Installing Redis"
      shell: |
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm repo update
          helm install ecsfin bitnami/redis-cluster --values /root/kube_additional/database/redis-values.yaml -n {{ redis_ns }} 
          kubectl apply -f /root/kube_additional/database/redisDnsMap.yaml -n {{ deployment_ns }}
      when: 
        - Redis == "enabled"       
      ignore_errors: yes      
          
